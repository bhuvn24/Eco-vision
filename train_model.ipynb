{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Waste management using cnn model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\kbhuv\\onedrive\\desktop\\cnn_waste_classification-main\\venv\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in c:\\users\\kbhuv\\onedrive\\desktop\\cnn_waste_classification-main\\venv\\lib\\site-packages (from opencv-python) (2.2.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'DOSKEY' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "import os, json, math, itertools, argparse, random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def set_seed(s=42):\n",
    "    random.seed(s); np.random.seed(s); tf.random.set_seed(s)\n",
    "\n",
    "def get_gens(train_dir, val_dir, img_size=224, batch=32):\n",
    "    train_aug = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=25,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,  # waste has weak orientation bias\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    val_aug = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    train_gen = train_aug.flow_from_directory(\n",
    "        train_dir, target_size=(img_size,img_size), batch_size=batch,\n",
    "        class_mode='categorical', shuffle=True)\n",
    "    val_gen = val_aug.flow_from_directory(\n",
    "        val_dir, target_size=(img_size,img_size), batch_size=batch,\n",
    "        class_mode='categorical', shuffle=False)\n",
    "    return train_gen, val_gen\n",
    "\n",
    "def compute_class_weights(generator):\n",
    "    counts = np.bincount(generator.classes)\n",
    "    total = counts.sum()\n",
    "    weights = {i: total/(len(counts)*c) for i,c in enumerate(counts)}\n",
    "    return weights\n",
    "\n",
    "def build_model(num_classes=2, lr=1e-4, trainable_at=None):\n",
    "    base = ResNet50(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "    if trainable_at is None:\n",
    "        base.trainable = False\n",
    "    else:\n",
    "        for layer in base.layers: layer.trainable = False\n",
    "        for layer in base.layers[trainable_at:]: layer.trainable = True\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base.output)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    out = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(base.input, out)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def plot_confmat(cm, classes, out_path):\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "    plt.imshow(cm, interpolation='nearest')\n",
    "    plt.title('Confusion Matrix'); plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45); plt.yticks(tick_marks, classes)\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max()/2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.ylabel('True label'); plt.xlabel('Predicted label')\n",
    "    plt.tight_layout(); plt.savefig(out_path, bbox_inches='tight'); plt.close(fig)\n",
    "\n",
    "def main(args):\n",
    "    set_seed()\n",
    "    os.makedirs(args.artifacts, exist_ok=True)\n",
    "    train_gen, val_gen = get_gens(args.train_dir, args.val_dir, batch=args.batch)\n",
    "\n",
    "    model = build_model(num_classes=2, lr=args.lr, trainable_at=args.unfreeze_at)\n",
    "\n",
    "    cweights = compute_class_weights(train_gen)\n",
    "\n",
    "    cbs = [\n",
    "        EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6),\n",
    "        ModelCheckpoint(os.path.join(args.artifacts, 'model.h5'), monitor='val_loss',\n",
    "                        save_best_only=True)\n",
    "    ]\n",
    "\n",
    "    steps_train = math.ceil(train_gen.samples / args.batch)\n",
    "    steps_val = math.ceil(val_gen.samples / args.batch)\n",
    "\n",
    "    hist = model.fit(\n",
    "        train_gen, steps_per_epoch=steps_train,\n",
    "        validation_data=val_gen, validation_steps=steps_val,\n",
    "        epochs=args.epochs, class_weight=cweights, callbacks=cbs, verbose=1\n",
    "    )\n",
    "\n",
    "    # Save history\n",
    "    with open(os.path.join(args.artifacts, 'history.json'), 'w') as f:\n",
    "        json.dump(hist.history, f)\n",
    "\n",
    "    # Eval + confusion matrix\n",
    "    val_gen.reset()\n",
    "    preds = model.predict(val_gen, steps=steps_val)\n",
    "    y_pred = preds.argmax(axis=1); y_true = val_gen.classes\n",
    "    target_names = list(val_gen.class_indices.keys())\n",
    "    print(classification_report(y_true, y_pred, target_names=target_names, digits=4))\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plot_confmat(cm, target_names, os.path.join(args.artifacts, 'confusion_matrix.png'))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    p = argparse.ArgumentParser()\n",
    "    p.add_argument(\"--train_dir\", type=str, required=True)  # e.g., data/TRAIN\n",
    "    p.add_argument(\"--val_dir\",   type=str, required=True)  # e.g., data/TEST  (binary set)\n",
    "    p.add_argument(\"--epochs\",    type=int, default=20)\n",
    "    p.add_argument(\"--batch\",     type=int, default=32)\n",
    "    p.add_argument(\"--lr\",        type=float, default=1e-4)\n",
    "    p.add_argument(\"--unfreeze_at\", type=int, default=None, help=\"e.g., 140 to fine-tune last blocks\")\n",
    "    p.add_argument(\"--artifacts\", type=str, default=\"artifacts\")\n",
    "    args = p.parse_args()\n",
    "    main(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\kbhuv\\onedrive\\desktop\\cnn_waste_classification-main\\venv\\lib\\site-packages (2.20.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\kbhuv\\onedrive\\desktop\\cnn_waste_classification-main\\venv\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\kbhuv\\onedrive\\desktop\\cnn_waste_classification-main\\venv\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\kbhuv\\onedrive\\desktop\\cnn_waste_classification-main\\venv\\lib\\site-packages (from tensorflow) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\kbhuv\\onedrive\\desktop\\cnn_waste_classification-main\\venv\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\kbhuv\\onedrive\\desktop\\cnn_waste_classification-main\\venv\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\kbhuv\\onedrive\\desktop\\cnn_waste_classification-main\\venv\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\kbhuv\\onedrive\\desktop\\cnn_waste_classification-main\\venv\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\kbhuv\\onedrive\\desktop\\cnn_waste_classification-main\\venv\\lib\\site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\kbhuv\\onedrive\\desktop\\cnn_waste_classification-main\\venv\\lib\\site-packages (from tensorflow) (6.33.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\kbhuv\\onedrive\\desktop\\cnn_waste_classification-main\\venv\\lib\\site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kbhuv\\onedrive\\desktop\\cnn_waste_classification-main\\venv\\lib\\site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\kbhuv\\onedrive\\desktop\\cnn_waste_classification-main\\venv\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\kbhuv\\onedrive\\desktop\\cnn_waste_classification-main\\venv\\lib\\site-packages (from tensorflow) (3.2.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\kbhuv\\onedrive\\desktop\\cnn_waste_classification-main\\venv\\lib\\site-packages (from tensorflow) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\kbhuv\\onedrive\\desktop\\cnn_waste_classification-main\\venv\\lib\\site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\kbhuv\\onedrive\\desktop\\cnn_waste_classification-main\\venv\\lib\\site-packages (from tensorflow) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\kbhuv\\onedrive\\desktop\\cnn_waste_classification-main\\venv\\lib\\site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\kbhuv\\onedrive\\desktop\\cnn_waste_classification-main\\venv\\lib\\site-packages (from tensorflow) (3.12.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\kbhuv\\onedrive\\desktop\\cnn_waste_classification-main\\venv\\lib\\site-packages (from tensorflow) (2.2.6)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\kbhuv\\onedrive\\desktop\\cnn_waste_classification-main\\venv\\lib\\site-packages (from tensorflow) (3.15.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\kbhuv\\onedrive\\desktop\\cnn_waste_classification-main\\venv\\lib\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\kbhuv\\onedrive\\desktop\\cnn_waste_classification-main\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kbhuv\\onedrive\\desktop\\cnn_waste_classification-main\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kbhuv\\onedrive\\desktop\\cnn_waste_classification-main\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kbhuv\\onedrive\\desktop\\cnn_waste_classification-main\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\kbhuv\\onedrive\\desktop\\cnn_waste_classification-main\\venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: pillow in c:\\users\\kbhuv\\onedrive\\desktop\\cnn_waste_classification-main\\venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (12.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\kbhuv\\onedrive\\desktop\\cnn_waste_classification-main\\venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\kbhuv\\onedrive\\desktop\\cnn_waste_classification-main\\venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\kbhuv\\onedrive\\desktop\\cnn_waste_classification-main\\venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\kbhuv\\onedrive\\desktop\\cnn_waste_classification-main\\venv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (14.2.0)\n",
      "Requirement already satisfied: namex in c:\\users\\kbhuv\\onedrive\\desktop\\cnn_waste_classification-main\\venv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\kbhuv\\onedrive\\desktop\\cnn_waste_classification-main\\venv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\kbhuv\\onedrive\\desktop\\cnn_waste_classification-main\\venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\kbhuv\\onedrive\\desktop\\cnn_waste_classification-main\\venv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\kbhuv\\onedrive\\desktop\\cnn_waste_classification-main\\venv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\kbhuv\\onedrive\\desktop\\cnn_waste_classification-main\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'DOSKEY' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "def set_seed(s=42):\n",
    "    random.seed(s); np.random.seed(s); tf.random.set_seed(s)\n",
    "\n",
    "def get_gens(train_dir, val_dir, img_size=224, batch=32):\n",
    "    train_aug = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=25,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,  # waste has weak orientation bias\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    val_aug = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    train_gen = train_aug.flow_from_directory(\n",
    "        train_dir, target_size=(img_size,img_size), batch_size=batch,\n",
    "        class_mode='categorical', shuffle=True)\n",
    "    val_gen = val_aug.flow_from_directory(\n",
    "        val_dir, target_size=(img_size,img_size), batch_size=batch,\n",
    "        class_mode='categorical', shuffle=False)\n",
    "    return train_gen, val_gen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\kbhuv\\onedrive\\desktop\\cnn_waste_classification-main\\venv\\lib\\site-packages (25.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'DOSKEY' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "def compute_class_weights(generator):\n",
    "    counts = np.bincount(generator.classes)\n",
    "    total = counts.sum()\n",
    "    weights = {i: total/(len(counts)*c) for i,c in enumerate(counts)}\n",
    "    return weights\n",
    "\n",
    "def build_model(num_classes=2, lr=1e-4, trainable_at=None):\n",
    "    base = ResNet50(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "    if trainable_at is None:\n",
    "        base.trainable = False\n",
    "    else:\n",
    "        for layer in base.layers: layer.trainable = False\n",
    "        for layer in base.layers[trainable_at:]: layer.trainable = True\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base.output)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    out = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(base.input, out)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def plot_confmat(cm, classes, out_path):\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "    plt.imshow(cm, interpolation='nearest')\n",
    "    plt.title('Confusion Matrix'); plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45); plt.yticks(tick_marks, classes)\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max()/2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.ylabel('True label'); plt.xlabel('Predicted label')\n",
    "    plt.tight_layout(); plt.savefig(out_path, bbox_inches='tight'); plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.10.7-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.3-cp312-cp312-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Using cached fonttools-4.60.1-cp312-cp312-win_amd64.whl.metadata (114 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.9-cp312-cp312-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\kbhuv\\onedrive\\desktop\\cnn_waste_classification-main\\venv\\lib\\site-packages (from matplotlib) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kbhuv\\onedrive\\desktop\\cnn_waste_classification-main\\venv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\kbhuv\\onedrive\\desktop\\cnn_waste_classification-main\\venv\\lib\\site-packages (from matplotlib) (12.0.0)\n",
      "Collecting pyparsing>=3 (from matplotlib)\n",
      "  Using cached pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\kbhuv\\onedrive\\desktop\\cnn_waste_classification-main\\venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kbhuv\\onedrive\\desktop\\cnn_waste_classification-main\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Using cached matplotlib-3.10.7-cp312-cp312-win_amd64.whl (8.1 MB)\n",
      "Using cached contourpy-1.3.3-cp312-cp312-win_amd64.whl (226 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.60.1-cp312-cp312-win_amd64.whl (2.3 MB)\n",
      "Using cached kiwisolver-1.4.9-cp312-cp312-win_amd64.whl (73 kB)\n",
      "Using cached pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "\n",
      "   ------ --------------------------------- 1/6 [kiwisolver]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   -------------------------- ------------- 4/6 [contourpy]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   ---------------------------------------- 6/6 [matplotlib]\n",
      "\n",
      "Successfully installed contourpy-1.3.3 cycler-0.12.1 fonttools-4.60.1 kiwisolver-1.4.9 matplotlib-3.10.7 pyparsing-3.2.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'DOSKEY' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "def main(args):\n",
    "    set_seed()\n",
    "    os.makedirs(args.artifacts, exist_ok=True)\n",
    "    train_gen, val_gen = get_gens(args.train_dir, args.val_dir, batch=args.batch)\n",
    "\n",
    "    model = build_model(num_classes=2, lr=args.lr, trainable_at=args.unfreeze_at)\n",
    "\n",
    "    cweights = compute_class_weights(train_gen)\n",
    "\n",
    "    cbs = [\n",
    "        EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6),\n",
    "        ModelCheckpoint(os.path.join(args.artifacts, 'model.h5'), monitor='val_loss',\n",
    "                        save_best_only=True)\n",
    "    ]\n",
    "\n",
    "    steps_train = math.ceil(train_gen.samples / args.batch)\n",
    "    steps_val = math.ceil(val_gen.samples / args.batch)\n",
    "\n",
    "    hist = model.fit(\n",
    "        train_gen, steps_per_epoch=steps_train,\n",
    "        validation_data=val_gen, validation_steps=steps_val,\n",
    "        epochs=args.epochs, class_weight=cweights, callbacks=cbs, verbose=1\n",
    "    )\n",
    "\n",
    "    # Save history\n",
    "    with open(os.path.join(args.artifacts, 'history.json'), 'w') as f:\n",
    "        json.dump(hist.history, f)\n",
    "\n",
    "    # Eval + confusion matrix\n",
    "    val_gen.reset()\n",
    "    preds = model.predict(val_gen, steps=steps_val)\n",
    "    y_pred = preds.argmax(axis=1); y_true = val_gen.classes\n",
    "    target_names = list(val_gen.class_indices.keys())\n",
    "    print(classification_report(y_true, y_pred, target_names=target_names, digits=4))\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plot_confmat(cm, target_names, os.path.join(args.artifacts, 'confusion_matrix.png'))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    p = argparse.ArgumentParser()\n",
    "    p.add_argument(\"--train_dir\", type=str, required=True)  # e.g., data/TRAIN\n",
    "    p.add_argument(\"--val_dir\",   type=str, required=True)  # e.g., data/TEST  (binary set)\n",
    "    p.add_argument(\"--epochs\",    type=int, default=20)\n",
    "    p.add_argument(\"--batch\",     type=int, default=32)\n",
    "    p.add_argument(\"--lr\",        type=float, default=1e-4)\n",
    "    p.add_argument(\"--unfreeze_at\", type=int, default=None, help=\"e.g., 140 to fine-tune last blocks\")\n",
    "    p.add_argument(\"--artifacts\", type=str, default=\"artifacts\")\n",
    "    args = p.parse_args()\n",
    "    main(args)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
